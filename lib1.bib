
@article{langton_self-reproduction_1984,
	title = {Self-reproduction in cellular automata},
	volume = {10},
	issn = {0167-2789},
	doi = {10.1016/0167-2789(84)90256-2},
	abstract = {Self-reproduction in cellular automata is discussed with reference to the models of von Neumann and Codd. The conclusion is drawn that although the capacity for universal construction is a sufficient condition for self-reproduction, it is not a necessary condition. Slightly more “liberal” criteria for what constitutes genuine self-reproduction are introduced, and a simple self-reproducing structure is exhibited which satisfies these new criteria. This structure achieves its simplicity by storing its description in a dynamic “loop”, rather than on a static “tape”.},
	number = {1},
	urldate = {2019-05-28},
	journal = {Physica D: Nonlinear Phenomena},
	author = {Langton, Christopher G.},
	month = jan,
	year = {1984},
	pages = {135--144},
}

@article{lempel_complexity_1976,
	title = {On the {Complexity} of {Finite} {Sequences}},
	volume = {22},
	issn = {0018-9448},
	doi = {10.1109/TIT.1976.1055501},
	abstract = {A new approach to the problem of evaluating the complexity ("randomness") of finite sequences is presented. The proposed complexity measure is related to the number of steps in a self-delimiting production process by which a given sequence is presumed to be generated. It is further related to the number of distinct substrings and the rate of their occurrence along the sequence. The derived properties of the proposed measure are discussed and motivated in conjunction with other well-established complexity criteria.},
	number = {1},
	journal = {IEEE Transactions on Information Theory},
	author = {Lempel, A. and Ziv, J.},
	month = jan,
	year = {1976},
	keywords = {Sequences},
	pages = {75--81}
}

@article{zenil_compression-based_2010,
	title = {Compression-{Based} {Investigation} of the {Dynamical} {Properties} of {Cellular} {Automata} and {Other} {Systems}},
	volume = {19},
	number = {1},
	urldate = {2019-06-18},
	journal = {Complex Systems},
	author = {Zenil, Hector},
	year = {2010},
}

@inproceedings{efros_texture_1999,
	address = {Kerkyra, Greece},
	title = {Texture synthesis by non-parametric sampling},
	isbn = {978-0-7695-0164-2},
	doi = {10.1109/ICCV.1999.790383},
	abstract = {A non-parametric method for texture synthesis is proposed. The texture synthesis process grows a new image outward from an initial seed, one pixel at a time. A Markov random ﬁeld model is assumed, and the conditional distribution of a pixel given all its neighbors synthesized so far is estimated by querying the sample image and ﬁnding all similar neighborhoods. The degree of randomness is controlled by a single perceptually intuitive parameter. The method aims at preserving as much local structure as possible and produces good results for a wide variety of synthetic and real-world textures.},
	language = {en},
	urldate = {2019-06-19},
	booktitle = {Proceedings of the {Seventh} {IEEE} {International} {Conference} on {Computer} {Vision}},
	author = {Efros, A.A. and Leung, T.K.},
	year = {1999},
	pages = {1033--1038 vol.2},
}

@inproceedings{miconi_virtual_2005,
	title = {A virtual creatures model for studies in artificial evolution},
	volume = {1},
	doi = {10.1109/CEC.2005.1554733},
	abstract = {We present the results of our replication of Karl Sims' work on the evolution of artificial creatures in a physically realistic 3D environment. We used standard McCulloch-Pitts neurons instead of a more complex set of ad hoc neurons, which we believe makes our model a more general tool for future experiments in artificial (co-)evolution. We provide a detailed description of our model and freely accessible source code. We describe our results both qualitatively and quantitatively, including an analysis of some evolved neural controllers. To the best of our knowledge, our work is the first replication of Sims' efforts to achieve results comparable to Sims' in efficiency and complexity, with standard neurons and realistic Newtonian physics},
	booktitle = {2005 {IEEE} {Congress} on {Evolutionary} {Computation}},
	author = {Miconi, T. and Channon, A.},
	month = sep,
	year = {2005},
	keywords = {artificial co-evolution, artificial creature evolution, Artificial intelligence, artificial life, biology computing, Computer science, evolution (biological), Evolutionary computation, Genetics, Intelligent robots, McCulloch-Pitts neurons, Morphology, neural controllers, neurocontrollers, Neurons, physically realistic 3D environment, Physics, Power system reliability, Testing, virtual creatures model, virtual reality},
	pages = {565--572 Vol.1},
}

@article{channon_improving_2003,
	title = {Improving and still passing the {ALife} test: {Component}-normalised activity statistics classify evolution in {Geb} as unbounded},
	shorttitle = {Improving and still passing the {ALife} test},
	journal = {Proceedings of Artificial Life VIII, Sydney},
	author = {Channon, Alastair},
	year = {2003},
	pages = {173--181},
}

@incollection{s_ray_approach_1991,
	edition = {1},
	title = {An approach to the synthesis of life},
	booktitle = {Artificial {Life} {II}},
	author = {S Ray, Thomas},
	month = jan,
	year = {1991},
	pages = {371--408},
}

@article{ofria_avida:_2004,
	title = {Avida: a software platform for research in computational evolutionary biology},
	volume = {10},
	issn = {1064-5462},
	shorttitle = {Avida},
	doi = {10.1162/106454604773563612},
	abstract = {Avida is a software platform for experiments with self-replicating and evolving computer programs. It provides detailed control over experimental settings and protocols, a large array of measurement tools, and sophisticated methods to analyze and post-process experimental data. We explain the general principles on which Avida is built, as well as its main components and their interactions. We also explain how experiments are set up, carried out, and analyzed.},
	language = {eng},
	number = {2},
	journal = {Artificial Life},
	author = {Ofria, Charles and Wilke, Claus O.},
	year = {2004},
	pmid = {15107231},
	keywords = {Biological Evolution, Computational Biology, Research Design, Software},
	pages = {191--229},
}

@inproceedings{soros_identifying_2014,
	title = {Identifying {Necessary} {Conditions} for {Open}-{Ended} {Evolution} through the {Artificial} {Life} {World} of {Chromaria}},
	booktitle = {Artificial {Life} 14: {Proceedings} of the {Fourteenth} {International} {Conference} on the {Synthesis} and {Simulation} of {Living} {Systems}},
	author = {Soros, Lisa B. and Stanley, Kenneth},
	year = {2014},
}

@inproceedings{yaeger_computational_1994,
	title = {Computational genetics, physiology, metabolism, neural systems, learning, vision, and behavior or {Poly} {World}: {Life} in a new context},
	volume = {17},
	shorttitle = {Computational genetics, physiology, metabolism, neural systems, learning, vision, and behavior or {Poly} {World}},
	booktitle = {Santa {Fe} {Institute} studies in the {Sciences} of {Complexity}},
	author = {Yaeger, Larry},
	year = {1994},
	pages = {263--263},
}

@inproceedings{spector_division_2007,
	series = {{GECCO} '07},
	title = {Division {Blocks} and the {Open}-ended {Evolution} of {Development}, {Form}, and {Behavior}},
	booktitle = {Proceedings of the 9th {Annual} {Conference} on {Genetic} and {Evolutionary} {Computation}},
	author = {Spector, Lee and Klein, Jon and Feinstein, Mark},
	year = {2007},
	keywords = {artificial life, breve, development, division blocks, morphology, open-ended evolution, recurrent networks},
	pages = {316--323},
}

@article{luvalle_effects_2019,
	title = {The {Effects} of {Boundary} {Conditions} on {Cellular} {Automata}},
	volume = {28},
	issn = {08912513},
	doi = {10.25088/ComplexSystems.28.1.97},
	language = {en},
	number = {1},
	urldate = {2019-06-21},
	journal = {Complex Systems},
	author = {LuValle, Brian J.},
	month = mar,
	year = {2019},
	pages = {97--124},
}

@inproceedings{mahoney_fast_2000,
	title = {Fast {Text} {Compression} with {Neural} {Networks}},
	abstract = {Neural networks have the potential to extend data compression algorithms beyond the character level n-gram models now in use, but have usually been avoided because they are too slow to be practical. We introduce a model that produces better compression than popular Limpel-Ziv compressors (zip, gzip, compress), and is competitive in time, space, and compression ratio with PPM and BurrowsWheeler algorithms, currently the best known. The compressor, a bit-level predictive arithmetic encoder using a 2 layer, 4 × 106 by 1 network, is fast (about 104 characters/second) because only 4-5 connections are simultaneously active and because it uses a variable learning rate optimized for one-pass training.},
	language = {en},
	booktitle = {{FLAIRS}},
	author = {Mahoney, Matthew V},
	year = {2000},
}

@article{mahoney_adaptive_2005,
	title = {Adaptive {Weighing} of {Context} {Models} for {Lossless} {Data} {Compression}},
	abstract = {Until recently the state of the art in lossless data compression was prediction by partial match (PPM). A PPM model estimates the next-symbol probability distribution by combining statistics from the longest matching contiguous contexts in which each symbol value is found. We introduce a context mixing model which improves on PPM by allowing contexts which are arbitrary functions of the history. Each model independently estimates a probability and confidence that the next bit of data will be 0 or 1. Predictions are combined by weighted averaging. After a bit is arithmetic coded, the weights are adjusted along the cost gradient in weight space to favor the most accurate models. Context mixing compressors, as implemented by the open source PAQ project, are now top ranked on several independent benchmarks.},
	language = {en},
	journal = {-},
	author = {Mahoney, Matthew V},
	year = {2005},
}

@article{mahoney_paq1_2002,
	title = {The {PAQ}1 data compression program},
	volume = {20},
	journal = {Draft, Jan},
	author = {Mahoney, Matthew V.},
	year = {2002},
}

@article{von_neumann_theory_1966,
	title = {Theory of self-reproducing automata},
	volume = {5},
	journal = {IEEE Transactions on Neural Networks},
	author = {Von Neumann, John and Burks, Arthur W.},
	year = {1966},
	pages = {3--14}
}

@article{wolfram_universality_1984,
	title = {Universality and complexity in cellular automata},
	volume = {10},
	issn = {0167-2789},
	doi = {10.1016/0167-2789(84)90245-8},
	abstract = {Cellular automata are discrete dynamical systems with simple construction but complex self-organizing behaviour. Evidence is presented that all one-dimensional cellular automata fall into four distinct universality classes. Characterizations of the structures generated in these classes are discussed. Three classes exhibit behaviour analogous to limit points, limit cycles and chaotic attractors. The fourth class is probably capable of universal computation, so that properties of its infinite time behaviour are undecidable.},
	number = {1},
	urldate = {2019-06-25},
	journal = {Physica D: Nonlinear Phenomena},
	author = {Wolfram, Stephen},
	month = jan,
	year = {1984},
	pages = {1--35},
}

@article{packard_two-dimensional_1985,
	title = {Two-dimensional cellular automata},
	volume = {38},
	language = {en},
	number = {5/6},
	journal = {Journal of Statistical Physics},
	author = {Packard, Norman H and Wolfram, Stephen},
	year = {1985},
}

@inproceedings{mikolov2016roadmap,
  title={A roadmap towards machine intelligence},
  author={Mikolov, Tomas and Joulin, Armand and Baroni, Marco},
  booktitle={International Conference on Intelligent Text Processing and Computational Linguistics},
  pages={29--61},
  year={2016},
  organization={Springer}
}


@inproceedings{booker_perspectives_2004,
	address = {New York, NY, USA},
	title = {Perspectives on {Adaptation} in {Natural} and {Artificial} {Systems}},
  booktitle = {{Proceedings} {Volume} in the {Santa} {Fe} {Institute} {Studies} in the {Sciences} of {Complexity}.},
	isbn = {978-0-19-516293-6},
	author = {Booker, Lashon},
	year = {2004}
}


@article{kolmogorov_three_1968,
	title = {Three approaches to the quantitative definition of information},
	volume = {2},
	issn = {0020-7160, 1029-0265},
	doi = {10.1080/00207166808803030},
	language = {en},
	number = {1-4},
	urldate = {2019-05-28},
	journal = {International Journal of Computer Mathematics},
	author = {Kolmogorov, A. N.},
	month = jan,
	year = {1968},
	pages = {157--168},
}


@book{grunwald_minimum_2007,
	address = {Cambridge, Mass},
	series = {Adaptive computation and machine learning},
	title = {The minimum description length principle},
	isbn = {978-0-262-07281-6},
	author = {Grünwald, Peter D.},
	year = {2007},
	keywords = {Minimum description length (Information theory)}
}


@article{krizhevsky_imagenet_2017,
	title = {{ImageNet} classification with deep convolutional neural networks},
	volume = {60},
	issn = {00010782},
	doi = {10.1145/3065386},
	abstract = {We trained a large, deep convolutional neural network to classify the 1.2 million high-resolution images in the ImageNet LSVRC-2010 contest into the 1000 different classes. On the test data, we achieved top-1 and top-5 error rates of 37.5\% and 17.0\% which is considerably better than the previous state-of-the-art. The neural network, which has 60 million parameters and 650,000 neurons, consists of ﬁve convolutional layers, some of which are followed by max-pooling layers, and three fully-connected layers with a ﬁnal 1000-way softmax. To make training faster, we used non-saturating neurons and a very efﬁcient GPU implementation of the convolution operation. To reduce overﬁtting in the fully-connected layers we employed a recently-developed regularization method called “dropout” that proved to be very effective. We also entered a variant of this model in the ILSVRC-2012 competition and achieved a winning top-5 test error rate of 15.3\%, compared to 26.2\% achieved by the second-best entry.},
	language = {en},
	number = {6},
	urldate = {2019-07-01},
	journal = {Communications of the ACM},
	author = {Krizhevsky, Alex and Sutskever, Ilya and Hinton, Geoffrey E.},
	month = may,
	year = {2017},
	pages = {84--90},
}


@inproceedings{sims_evolving_1994,
	title = {Evolving virtual creatures},
	doi = {10.1145/192161.192167},
	abstract = {This paper describes a novel system for creating virtual creatures that move and behave in simulated three-dimensional physical worlds. The morphologies of creatures and the neural systems for controlling their muscle forces are both generated automatically using genetic algorithms. Different fitness evaluation functions are used to direct simulated evolutions towards specific behaviors such as swimming, walking, jumping, and following.
A genetic language is presented that uses nodes and connections as its primitive elements to represent directed graphs, which are used to describe both the morphology and the neural circuitry of these creatures. This genetic language defines a hyperspace containing an indefinite number of possible creatures with behaviors, and when it is searched using optimization techniques, a variety of successful and interesting locomotion strategies emerge, some of which would be difficult to invent or built by design.},
	booktitle = {{SIGGRAPH}},
	author = {Sims, Karl},
	year = {1994},
	keywords = {Artificial neural network, Directed graph, Electronic circuit, Genetic algorithm, Mathematical morphology, Mathematical optimization, Simulation, Virtual world},
}


@article{schmidhuber_sequential_1996,
	title = {Sequential neural text compression},
	volume = {7},
	issn = {1045-9227},
	doi = {10.1109/72.478398},
	abstract = {The purpose of this paper is to show that neural networks may be promising tools for data compression without loss of information. We combine predictive neural nets and statistical coding techniques to compress text files. We apply our methods to certain short newspaper articles and obtain compression ratios exceeding those of the widely used Lempel-Ziv algorithms (which build the basis of the UNIX functions "compress" and "gzip"). The main disadvantage of our methods is that they are about three orders of magnitude slower than standard methods.},
	number = {1},
	journal = {IEEE Transactions on Neural Networks},
	author = {Schmidhuber, J. and Heil, S.},
	month = jan,
	year = {1996},
	keywords = {Arithmetic, backpropagation, Character generation, Compression algorithms, data compression, Decoding, document handling, encoding, feedforward neural nets, feedforward neural networks, file organisation, History, Huffman coding, Hydrogen, linear predictive coding, Neural networks, predictive neural networks, probability, probability distribution, Probability distribution, sequential text compression, statistical coding, Table lookup},
	pages = {142--146},
}


@article{langton_computation_1990,
	title = {Computation at the edge of chaos: {Phase} transitions and emergent computation},
	volume = {42},
	issn = {01672789},
	shorttitle = {Computation at the edge of chaos},
	doi = {10.1016/0167-2789(90)90064-V},
	language = {en},
	number = {1-3},
	urldate = {2019-04-25},
	journal = {Physica D: Nonlinear Phenomena},
	author = {Langton, Chris G.},
	month = jun,
	year = {1990},
	pages = {12--37},
}



@incollection{bennett_logical_1995,
	address = {Vienna},
	title = {Logical {Depth} and {Physical} {Complexity}},
	volume = {2},
	isbn = {978-3-211-82637-9 978-3-7091-6597-3},
	abstract = {Some mathematical and natural objects (a random sequence, a sequence of zeros, a perfect crystal, a gas) are intuitively trivial, while others (e.g. the human body, the digits of π) contain internal evidence of a nontrivial causal history.},
	language = {en},
	urldate = {2019-09-05},
	booktitle = {The {Universal} {Turing} {Machine} {A} {Half}-{Century} {Survey}},
	author = {Bennett, Charles H.},
	editor = {Herken, Rolf and Herken, Rolf},
	year = {1995},
	doi = {10.1007/978-3-7091-6597-3_8},
	pages = {207--235},
}


@article{zenil_image_2012,
	title = {Image characterization and classification by physical complexity},
	volume = {17},
	copyright = {Copyright © 2011 Wiley Periodicals, Inc.},
	issn = {1099-0526},
	doi = {10.1002/cplx.20388},
	abstract = {We present a method for estimating the complexity of an image based on Bennett's concept of logical depth. Bennett identified logical depth as the appropriate measure of organized complexity, and hence as being better suited to the evaluation of the complexity of objects in the physical world. Its use results in a different, and in some sense a finer characterization than is obtained through the application of the concept of Kolmogorov complexity alone. We use this measure to classify images by their information content. The method provides a means for classifying and evaluating the complexity of objects by way of their visual representations. To the authors' knowledge, the method and application inspired by the concept of logical depth presented herein are being proposed and implemented for the first time. © 2011 Wiley Periodicals, Inc. Complexity, 2011},
	language = {en},
	number = {3},
	urldate = {2019-09-04},
	journal = {Complexity},
	author = {Zenil, Hector and Delahaye, Jean-Paul and Gaucherel, Cédric},
	year = {2012},
	keywords = {algorithmic complexity, algorithmic randomness, Bennett's logical depth, image classification, information content},
	pages = {26--42},
}

@article{zenil_two-dimensional_2015,
	title = {Two-dimensional {Kolmogorov} complexity and an empirical validation of the {Coding} theorem method by compressibility},
	volume = {1},
	issn = {2376-5992},
	doi = {10.7717/peerj-cs.23},
	abstract = {We propose a measure based upon the fundamental theoretical concept in algorithmic information theory that provides a natural approach to the problem of evaluating n-dimensional complexity by using an n-dimensional deterministic Turing machine. The technique is interesting because it provides a natural algorithmic process for symmetry breaking generating complex n-dimensional structures from perfectly symmetric and fully deterministic computational rules producing a distribution of patterns as described by algorithmic probability. Algorithmic probability also elegantly connects the frequency of occurrence of a pattern with its algorithmic complexity, hence effectively providing estimations to the complexity of the generated patterns. Experiments to validate estimations of algorithmic complexity based on these concepts are presented, showing that the measure is stable in the face of some changes in computational formalism and that results are in agreement with the results obtained using lossless compression algorithms when both methods overlap in their range of applicability. We then use the output frequency of the set of 2-dimensional Turing machines to classify the algorithmic complexity of the space-time evolutions of Elementary Cellular Automata.},
	language = {en},
	urldate = {2019-09-10},
	journal = {PeerJ Computer Science},
	author = {Zenil, Hector and Soler-Toscano, Fernando and Delahaye, Jean-Paul and Gauvrit, Nicolas},
	month = sep,
	year = {2015},
}

@article{bilotta_artificial_2011,
	title = {{ARTIFICIAL} {MICRO}-{WORLDS} {PART} {I}: {A} {NEW} {APPROACH} {FOR} {STUDYING} {LIFE}-{LIKE} {PHENOMENA}},
	volume = {21},
	issn = {0218-1274, 1793-6551},
	shorttitle = {{ARTIFICIAL} {MICRO}-{WORLDS} {PART} {I}},
	doi = {10.1142/S0218127411028659},
	language = {en},
	number = {02},
	urldate = {2019-09-02},
	journal = {International Journal of Bifurcation and Chaos},
	author = {Bilotta, Eleonora and Pantano, Pietro and Vena, Stefano},
	month = feb,
	year = {2011},
	pages = {373--398},
}


@article{soler-toscano_calculating_2014,
	title = {Calculating {Kolmogorov} {Complexity} from the {Output} {Frequency} {Distributions} of {Small} {Turing} {Machines}},
	volume = {9},
	issn = {1932-6203},
	doi = {10.1371/journal.pone.0096223},
	abstract = {Drawing on various notions from theoretical computer science, we present a novel numerical approach, motivated by the notion of algorithmic probability, to the problem of approximating the Kolmogorov-Chaitin complexity of short strings. The method is an alternative to the traditional lossless compression algorithms, which it may complement, the two being serviceable for different string lengths. We provide a thorough analysis for all binary strings of length and for most strings of length by running all Turing machines with 5 states and 2 symbols ( with reduction techniques) using the most standard formalism of Turing machines, used in for example the Busy Beaver problem. We address the question of stability and error estimation, the sensitivity of the continued application of the method for wider coverage and better accuracy, and provide statistical evidence suggesting robustness. As with compression algorithms, this work promises to deliver a range of applications, and to provide insight into the question of complexity calculation of finite (and short) strings. Additional material can be found at the Algorithmic Nature Group website at http://www.algorithmicnature.org. An Online Algorithmic Complexity Calculator implementing this technique and making the data available to the research community is accessible at http://www.complexitycalculator.com.},
	language = {en},
	number = {5},
	urldate = {2019-06-06},
	journal = {PLOS ONE},
	author = {Soler-Toscano, Fernando and Zenil, Hector and Delahaye, Jean-Paul and Gauvrit, Nicolas},
	month = may,
	year = {2014},
	keywords = {Algorithms, Approximation methods, Computer and information sciences, Computer applications, Graph theory, Information theory, Internet, Probability distribution},
}


@article{zenil_what_2014,
	title = {What {Is} {Nature}-{Like} {Computation}? {A} {Behavioural} {Approach} and a {Notion} of {Programmability}},
	volume = {27},
	issn = {2210-5441},
	shorttitle = {What {Is} {Nature}-{Like} {Computation}?},
	doi = {10.1007/s13347-012-0095-2},
	abstract = {The aim of this paper is to propose an alternative behavioural definition of computation (and of a computer) based simply on whether a system is capable of reacting to the environment—the input—as reflected in a measure of programmability. This definition is intended to have relevance beyond the realm of digital computers, particularly vis-à-vis natural systems. This will be done by using an extension of a phase transition coefficient previously defined in an attempt to characterise the dynamical behaviour of cellular automata and other systems. The transition coefficient measures the sensitivity of a system to external stimuli and will be used to define the susceptibility of a system to be (efficiently) programmed.},
	language = {en},
  number = {3},
  urldate = {2019-09-05},
	journal = {Philosophy \& Technology},
	author = {Zenil, Hector},
	month = sep,
	year = {2014},
	keywords = {Cellular automata, Compressibility, Natural computation, Philosophy of computation, Programmability, Turing universality},
	pages = {399--421},
}

@inproceedings{pathak_learning_2019,
	title = {Learning to {Control} {Self}-{Assembling} {Morphologies}: {A} {Study} of {Generalization} via {Modularity}},
	abstract = {Contemporary sensorimotor learning approaches typically start with an existing complex agent (e.g., a robotic arm), which they learn to control. In contrast, this paper investigates a modular co-evolution strategy: a collection of primitive agents learns to dynamically self-assemble into composite bodies while also learning to coordinate their behavior to control these bodies. Each primitive agent consists of a limb with a motor attached at one end. Limbs may choose to link up to form collectives. When a limb initiates a link-up action and there is another limb nearby, the latter is magnetically connected to the ‘parent’ limb’s motor. This forms a new single agent, which may further link with other agents. In this way, complex morphologies can emerge, controlled by a policy whose architecture is in explicit correspondence with the morphology. We evaluate the performance of these dynamic and modular agents in simulated environments. We demonstrate better generalization to test-time changes both in the environment, as well as in the structure of the agent, compared to static and monolithic baselines. Project video and code are available at https://pathak22.github.io/modular-assemblies/.},
	language = {en},
	booktitle = {{NeurIPS}},
	author = {Pathak, Deepak and Lu, Chris and Darrell, Trevor and Isola, Phillip and Efros, Alexei A},
	year = {2019},
}


@inproceedings{kowaliw_measures_2008,
	title = {Measures of complexity for artificial embryogeny},
	booktitle = {Proceedings of the 10th annual conference on {Genetic} and evolutionary computation - {GECCO} '08},
	publisher = {ACM Press},
	author = {Kowaliw, Taras},
	year = {2008},
}


@article{li_transition_1990,
	title = {Transition phenomena in cellular automata rule space},
	volume = {45},
	journal = {Physica D: Nonlinear Phenomena},
	author = {Li, Wentian and Packard, Norman H. and Langton, Chris G.},
	year = {1990},
	pages = {77--94},
}

@article{zenil_asymptotic_2013,
	title = {Asymptotic behavior and ratios of complexity in cellular automata},
	volume = {23},
	number = {09},
	journal = {International Journal of Bifurcation and Chaos},
	author = {Zenil, Hector and Villarreal-Zapata, Elena},
	year = {2013},
}


@inproceedings{grassberger_randomness_1989,
	title = {Randomness, {Information}, and {Complexity}},
	language = {en},
	booktitle = {Proceedings of the 5th {Mexican} {School} on {Statistical} {Physics}},
	author = {Grassberger, Peter},
	year = {1989},
}